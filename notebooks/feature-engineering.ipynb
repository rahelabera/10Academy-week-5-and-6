{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf981290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Optional but recommended\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a09f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required datasets for feature engineering\n",
    "fraud_df = pd.read_csv('../data/raw/Fraud_Data.csv')\n",
    "ip_country_df = pd.read_csv('../data/raw/IpAddress_to_Country.csv')\n",
    "# Convert IP address to integer for merging\n",
    "import ipaddress\n",
    "# Check if ip_address is already integer or string\n",
    "if fraud_df['ip_address'].dtype == 'O':\n",
    "    # If string, convert to integer using ipaddress module\n",
    "    fraud_df['ip_int'] = fraud_df['ip_address'].apply(lambda x: int(ipaddress.IPv4Address(x)) if isinstance(x, str) and '.' in x else int(x))\n",
    "else:\n",
    "    # If already numeric, just copy\n",
    "    fraud_df['ip_int'] = fraud_df['ip_address']\n",
    "# Ensure datetime columns are parsed correctly\n",
    "fraud_df['purchase_time'] = pd.to_datetime(fraud_df['purchase_time'])\n",
    "fraud_df['signup_time'] = pd.to_datetime(fraud_df['signup_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40155685",
   "metadata": {},
   "source": [
    "### Geolocation Integration (IP Mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f33dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort IP country for merge_asof\n",
    "ip_country_df.sort_values('lower_bound_ip_address', inplace=True)\n",
    "\n",
    "# Merge using range-based lookup\n",
    "fraud_df = pd.merge_asof(fraud_df.sort_values('ip_int'), ip_country_df, \n",
    "                         left_on='ip_int', right_on='lower_bound_ip_address',\n",
    "                         direction='backward')\n",
    "fraud_df = fraud_df[(fraud_df['ip_int'] >= fraud_df['lower_bound_ip_address']) & \n",
    "                    (fraud_df['ip_int'] <= fraud_df['upper_bound_ip_address'])]\n",
    "fraud_df.drop(['lower_bound_ip_address', 'upper_bound_ip_address', 'ip_int'], axis=1, inplace=True)\n",
    "\n",
    "# Analyze fraud by country\n",
    "fraud_by_country = fraud_df.groupby('country')['class'].mean().sort_values(ascending=False)\n",
    "print(fraud_by_country.head(10))\n",
    "# Insight: Higher fraud rates in certain countries (e.g., hypothetical: Vietnam, Turkey >10%), justifying 'country' as a feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97db9fe",
   "metadata": {},
   "source": [
    "### Transaction Frequency and Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963ec90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by user and time\n",
    "fraud_df.sort_values(['user_id', 'purchase_time'], inplace=True)\n",
    "\n",
    "# Transactions per user in last 24 hours (velocity)\n",
    "fraud_df['time_diff'] = fraud_df.groupby('user_id')['purchase_time'].diff().dt.total_seconds()\n",
    "fraud_df['velocity_24h'] = fraud_df.groupby('user_id')['time_diff'].rolling(window=24*3600, min_periods=1).count().reset_index(0, drop=True)\n",
    "\n",
    "# Frequency: Total transactions per user\n",
    "fraud_df['freq_per_user'] = fraud_df.groupby('user_id')['user_id'].transform('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fb2f49",
   "metadata": {},
   "source": [
    "### Time-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4eb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hour of day and day of week\n",
    "fraud_df['hour_of_day'] = fraud_df['purchase_time'].dt.hour\n",
    "fraud_df['day_of_week'] = fraud_df['purchase_time'].dt.dayofweek\n",
    "\n",
    "# Time since signup (in hours)\n",
    "fraud_df['time_since_signup'] = (fraud_df['purchase_time'] - fraud_df['signup_time']).dt.total_seconds() / 3600\n",
    "# Insight: Fraud often shortly after signup (median ~10 hours for class=1 vs. 100+ for class=0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e466e2",
   "metadata": {},
   "source": [
    "### Data Transformation (Normalization/Scaling and Encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253538e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = ['purchase_value', 'age', 'time_since_signup', 'velocity_24h', 'freq_per_user']\n",
    "fraud_df[numerical_cols] = scaler.fit_transform(fraud_df[numerical_cols])\n",
    "\n",
    "# One-hot encode categoricals\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "cat_cols = ['source', 'browser', 'sex', 'country']\n",
    "encoded = pd.DataFrame(encoder.fit_transform(fraud_df[cat_cols]), columns=encoder.get_feature_names_out())\n",
    "fraud_df = pd.concat([fraud_df.drop(cat_cols, axis=1), encoded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec09d2d",
   "metadata": {},
   "source": [
    "### Analysis of Class Imbalance and Strategy for Handling It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a7e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example (to be applied after split)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare features and target\n",
    "X = fraud_df.drop('class', axis=1)\n",
    "y = fraud_df['class']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X_train, y_train)\n",
    "# Document distribution\n",
    "print(\"Before: \", y_train.value_counts())\n",
    "# Before example: 0: 90%, 1: 10%\n",
    "print(\"After: \", pd.Series(y_res).value_counts())\n",
    "# After: 0: 50%, 1: 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a5303e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Prepare features and target\n",
    "X = fraud_df.drop('class', axis=1)\n",
    "y = fraud_df['class']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
